{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80578317",
   "metadata": {},
   "source": [
    "You have been provided with a multi dimensional data that contains information on certain images. Using machine learning, \n",
    "you should be able to predict the images on the new set of data using the model that you have trained on the existing data. \n",
    "\n",
    "Dataset Information: Each point in the data is an 8×8 image.\n",
    "\n",
    "Classes\t10\n",
    "Samples per class\t~180\n",
    "Samples total\t1797\n",
    "Dimensionality\t64\n",
    "Features\tintegers 0-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "117c16f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) What will be the output of the following code? \n",
    "# from sklearn import dataset  \n",
    "# digits = datasets.load_digits()\n",
    "\n",
    "# Digits data in a pandas dataframe\n",
    "# Value error\n",
    "# Import error\n",
    "# Digits data from the sklearn module  #ans\n",
    "\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "360199dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) If we split the data in a ratio of 80% training and 20% testing data, what will be the correct code for the same?\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=80:20, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)   anss\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=80, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f9f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) In the train_test_split, if we keep the random_state = 1, what does it mean for our training and testing data?\n",
    "# Both 1 and 2.\n",
    "# Everytime the new random values are generated in the test and train sets\n",
    "# The values will be the same every time the code is executed in the testing and training sets.  ans\n",
    "# None of the Above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1006d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) In the code below, where we standardize the data, we have used the fit_transform() for the training sample, \n",
    "# and transform() for the testing sample, why?\n",
    "# sc = StandardScaler()\n",
    "# X_train = sc.fit_transform(X_train)\n",
    "# X_test = sc.transform(X_test)\n",
    "\n",
    "# We use the same mean and variance calculated on the training data to fit the test data     ans\n",
    "# The methods distinguish between the variance of each class\n",
    "# The methods distinguish between mean and standard deviation of each class.\n",
    "# None of the above\n",
    "\n",
    "#  It's important to fit the scaler (StandardScaler in this case) on the training data only to prevent data leakage. Then, \n",
    "# we transform both the training and testing data using the mean and variance calculated from the training data to maintain consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20dc5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Find the mistake in the code below?  \n",
    "# lda = LinearDiscriminantAnalysis(n_components=9)\n",
    "# X_train = lda.fit_transform(X_train) \n",
    "# X_test = lda.transform(X_test)\n",
    "# Both 1 and 2\n",
    "# Fit_transform() must include the y_train.\n",
    "# None of the above                                            ans\n",
    "# transform() must include the y_train.\n",
    "\n",
    "#The code is correctly performing Linear Discriminant Analysis (LDA) on the training and testing data to reduce dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1efcf49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Split the data in 80: 20 ratios, then Standardize and perform LDA. What would be the shape of the X_train data,\n",
    "#     after doing all the mentioned operations?\n",
    "# (1797,64)\n",
    "# (1437,9)      ans\n",
    "# (1437,)\n",
    "# (1437,64)\n",
    "\n",
    "#Explanation: After splitting the data, standardizing it, and performing LDA with n_components=9, \n",
    "#the shape of X_train would be (1437, 9), indicating 1437 samples with 9 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a9eb3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Which of the following is a common application of LDA?\n",
    "# Document classification\n",
    "# Fraud detection\n",
    "# Topic modeling of social media data\n",
    "# All of the above   ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fd0ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) How do you decide the n_components in the LinearDiscriminantAnalaysis()?\n",
    "# Correlation coefficient\n",
    "# None of the above\n",
    "# variation inflation factor\n",
    "# (no. of classes) -1  ans\n",
    "\n",
    "#Explanation: The number of discriminant components (n_components) in LDA is typically set to\n",
    "# one less than the number of classes to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "625aff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) If we keep the n_components as 15 in the LDA, what will be the shape of the X_train data?\n",
    "# (15,15)\n",
    "# (1437, 15)  anss\n",
    "# (15,)\n",
    "# (1797,15)\n",
    "\n",
    "# If n_components is set to 15 in LDA, the shape of X_train would be (1437, 15), indicating 1437 samples with 15 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd1da9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) After performing LDA on the standardized data, with n_components= 9,\n",
    "# Create a random forest classifier to fit the new data with n_estimators= 100, and random_state =42.\n",
    "# After the above operation, what will be the accuracy score of the model?\n",
    "\n",
    "# 90 % and above   ans \n",
    "# 85%\n",
    "# 80%\n",
    "# 55% to 75%\n",
    "\n",
    "# Random Forest Classifier is a powerful model, and with sufficient data and suitable parameters, \n",
    "# it often achieves high accuracy. Therefore, it's reasonable to expect an accuracy score of 90% and above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0a04bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11)  Identify the mistake in the code below.\n",
    "# from sklearn.ensemble import RandomForestClassifier  \n",
    "# rf = RandomForestClassifier(n_estimators=100, random_state=42)  \n",
    "# rf.fit(X_train, X_test)\n",
    "\n",
    "\n",
    "# Missing parameter - random_state=42\n",
    "# X_test instead of y_test\n",
    "# X_test instead of y_train                ans\n",
    "# X_test instead of n_components = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91b3f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) What percentage of positive cases was the model able to catch for class 6?\n",
    "# 99\n",
    "# 100\n",
    "# 35\n",
    "# 97  ans\n",
    "\n",
    "# This question refers to the recall or sensitivity metric, which calculates the percentage of actual positive cases (class 6) \n",
    "# that were correctly identified by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4343a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) What percentage of the predictions were true for class 5?\n",
    "# 47 -50\n",
    "# 97-99\n",
    "# 80-84\n",
    "# 93-95  ans\n",
    "\n",
    "#This question refers to the precision metric, which calculates the percentage of positive predictions (class 5)\n",
    "# that were correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f975756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14) What percentage of positive predictions were correct for class 3?\n",
    "# 34 -45\n",
    "# 80-84  ans\n",
    "# 92 -67\n",
    "# 94-97\n",
    "\n",
    "#This question also refers to the precision metric, which calculates the percentage of positive predictions (class 3)\n",
    "#that were correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5edc162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15) What is the criteria used by LDA for dimensionality reduction?\n",
    "# Minimize the variation within each class  ans\n",
    "# Minimize the mean within each class\n",
    "# None of the above.\n",
    "# Maximize the variation within each class  \n",
    "\n",
    "# LDA aims to maximize the separation between classes by reducing dimensionality \n",
    "# while preserving class discriminatory information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67bae8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16) Is the following statement true or false? \n",
    "# “LDA minimizes the distance between means of each class for dimensionality reduction”\n",
    "# FALSE  ans\n",
    "# TRUE\n",
    "\n",
    "#LDA maximizes the distance between class means, not minimizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34454fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17) Which of the following assumptions is made in Linear discriminant analysis?\n",
    "# Data is negatively skewed\n",
    "# Data is positively skewed\n",
    "# Data is non-stationary\n",
    "# Data is normally distributed  ans\n",
    "\n",
    "#LDA assumes that the data follows a multivariate normal distribution within each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb63cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18) Which of the following statements is true?\n",
    "# LDA assumes that the data is negatively skewed.\n",
    "# None of the above.\n",
    "# LDA assumes that each class has an identical covariance matrices.  anss\n",
    "# LDA assumes that none of the classes has identical covariance matrices.\n",
    "\n",
    "#: LDA assumes that all classes share the same covariance matrix, \n",
    "# which is a simplifying assumption to compute linear decision boundaries efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be4c682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19) Use Pokemon.csv for the question below, remove the ‘name’ column and do not perform any data cleaning or \n",
    "#data preprocessing before answering the question. If we split the data in a ratio of 80% training and 20% testing data,\n",
    "#what will be the correct code for the same?\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=80:20, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=20, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  ans\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=80, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e10e7b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20) Use Pokemon.csv for the question below, remove the ‘name’ column and do not perform any data cleaning or \n",
    "#data preprocessing before answering the question. Considering we are having 10 features and 3 classes in the target variable,\n",
    "#what is the range of values, components will take in LDA?\n",
    "# 1 to 3\n",
    "# 1 to 2  ans\n",
    "# 1 to 10\n",
    "# 1 to 9\n",
    "\n",
    "#In LDA, the number of components (n_components) can range from 1 to the minimum of (number of classes - 1) or\n",
    "# (number of features). In this case, it will range from 1 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48e8f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21) Use Pokemon.csv for the question below, remove ‘name’ column and do not perform any data cleaning or \n",
    "#data preprocessing before answering the question.\n",
    "#Consider we are having 8 features and 12 classes in target variable, what is the range of values, components will take in LDA?\n",
    "# 1 to 7\n",
    "# 1 to 12\n",
    "# 1 to 11  ans\n",
    "# 1 to 8\n",
    "\n",
    "# In LDA, the number of components (n_components) can range from 1 to the minimum of (number of classes - 1) or (number of features). In this case, it will range from 1 to 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad639f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 22) How do you decide the n_components in the LinearDiscriminantAnalaysis\n",
    "# variance\n",
    "# Correlation coefficient\n",
    "# explained_variance_ratio\n",
    "# variation inflation factor\n",
    "\n",
    "#Answer: (no. of classes) - 1\n",
    "#Reason: In LDA, the number of discriminant components (n_components) is typically set to one less than the number of classes to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbd0ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23) LDA assumes that the covariance matrices of all classes are equal\n",
    "# FALSE    \n",
    "# TRUE \n",
    "#Reason: LDA assumes that all classes share the same covariance matrix, not necessarily equal covariance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08aa11a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24) What are the methods that are used to to handle non-linearly separable data in LDA\n",
    "# Kernel LDA  ans\n",
    "# Ensemble methods\n",
    "# Regressor\n",
    "# LLE\n",
    "\n",
    "# Kernel LDA is an extension of LDA that allows it to handle non-linearly separable data by transforming the data into\n",
    "# a higher-dimensional space using kernel methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24fb0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25) On what basis the features are constructed in LDA\n",
    "# minimizes the differences between classes and minimizes the variations within each class.\n",
    "# minimizes the differences between classes and maximizes the variations within each class.\n",
    "# maximizes the differences between classes and maximizes the variations within each class.\n",
    "# maximizes the differences between classes and minimizes the variations within each class  ans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7fbb6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26). Which of the dominant independent features that significantly influences the separability of the class fighting \n",
    "# in LDA preprojection post performing below operations? Store column type (Target variable) as y Store Remaining columns\n",
    "# as X Normalize the X and get X_norm using normalize in sklearn.preprocessing Apply LDA with n_components as 5 \n",
    "# Display LDA coefficients\n",
    "# attack  ans\n",
    "# defense\n",
    "# sp_defense\n",
    "# sp_attack\n",
    "\n",
    "#LDA coefficients represent the contributions of each feature to the linear discriminant functions. \n",
    "#A higher absolute coefficient value indicates a stronger influence of that feature on the separation of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc485e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27)Using the LDA coefficients obtained from question 8 , \n",
    "# analyze the coefficient magnitudes and their influences on the separability of the ‘bug’ class.\n",
    "# Choose the appropriate description that characterizes the magnitude and separability relationship\n",
    "\n",
    "# High magnitude and Not Linearly separable  \n",
    "# High magnitude and Linearly separable  ans\n",
    "# Low magnitude and Linearly separable\n",
    "# Low magnitude and Not Linearly separable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
